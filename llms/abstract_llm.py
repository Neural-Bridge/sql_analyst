from abc import ABC, abstractmethod
from typing import Any, List, Optional
from langchain_core.callbacks import CallbackManagerForLLMRun
from langchain_core.messages import BaseMessage
from langchain_core.language_models import SimpleChatModel
from langchain_community.adapters.openai import convert_message_to_dict


class AbstractLLM(SimpleChatModel, ABC):
  """
  Abstract base class for Language Learning Models (LLMs).

  This class provides a common interface and structure for all LLMs.
  Subclasses of AbstractLLM should implement the `initialize_client` and `call_internal` methods.

  Attributes:
    _llm_type (str): The type of the LLM.
  """

  def __init__(self):
    super().__init__()
    self.initialize_client()

  def _call(
    self,
    messages: List[BaseMessage],
    stop: Optional[List[str]] = None,
    run_manager: Optional[CallbackManagerForLLMRun] = None,
    **kwargs: Any,
  ) -> str:
    """
    Calls the LLM with the given messages.

    Args:
      messages (List[BaseMessage]): The list of messages to be passed to the LLM.
      stop (Optional[List[str]]): The list of stop words to be used during the LLM call.
      run_manager (Optional[CallbackManagerForLLMRun]): The callback manager for the LLM run.
      **kwargs (Any): Additional keyword arguments to be passed to the LLM.

    Returns:
      str: The response generated by the LLM.
    """
    formatted_messages = [convert_message_to_dict(m) for m in messages]
    return self.call_internal(messages=formatted_messages, **kwargs)

  @abstractmethod
  def initialize_client(self):
    """
    Abstract method to initialize the LLM client.
    """
    pass

  @abstractmethod
  def call_internal(self, messages: list[dict]) -> str:
    """
    Abstract method to make the internal LLM call.

    Args:
      messages (list[dict]): Representing the conversation history to be passed to the LLM.
      Each dict in the list generally have a 'content' which is the text message,
      and a 'role' which is the role of the message. that is either 'user' or 'assistant'.

    Returns:
      str: The response text generated by the LLM.
    """
    pass

  @property
  def _llm_type(self) -> str:
    """
    Returns the type of the LLM. Just to match langchain format requirement for llms.

    Returns:
      str: The type of the LLM.
    """
    return self.__class__.__name__




